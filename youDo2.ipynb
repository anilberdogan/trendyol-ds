{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf91fa1",
   "metadata": {},
   "source": [
    "# You Do 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f5559",
   "metadata": {},
   "source": [
    "Importing libraries and reading movielens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73191ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-57d858efa56c>:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('https://files.grouplens.org/datasets/movielens/ml-100k/u.data', delimiter=r'\\t',\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://files.grouplens.org/datasets/movielens/ml-100k/u.data', delimiter=r'\\t',\n",
    "names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "R = df.pivot(index='user_id', columns='item_id', values='rating').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8002e094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3.,  4., ..., nan, nan, nan],\n",
       "       [ 4., nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [ 5., nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan,  5., nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37ef22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need indexes of non-zero elements to train and score on.\n",
    "irow, jcol = np.where(~np.isnan(R))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd5d626",
   "metadata": {},
   "source": [
    "Train, validation and test split. I used validation set to optimize lambda hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb987013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(R,irow,jcol):\n",
    "    idx_all = np.random.choice(np.arange(100_000), 2000, replace=False)\n",
    "    idx = np.random.choice(np.arange(2000), 1000, replace=False)\n",
    "    val_idx = [val_id for val_id in idx_all if val_id not in idx]\n",
    "    test_irow = irow[idx]\n",
    "    test_jcol = jcol[idx]\n",
    "    val_irow = irow[val_idx]\n",
    "    val_jcol = jcol[val_idx]\n",
    "    R_copy = R.copy()\n",
    "    R_copy[test_irow, test_jcol] = np.nan\n",
    "    R_copy[val_irow, val_jcol] = np.nan\n",
    "    R_test_mask = R.copy() # Will be used only dor prediction\n",
    "    R_test_mask[test_irow, test_jcol] = np.nan\n",
    "    return R_copy, test_irow, test_jcol, val_irow, val_jcol, R_test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "434a5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss(b_user, b_item, R, irow, jcol):\n",
    "    loss = 0\n",
    "    for i, j in zip(irow, jcol):\n",
    "        if np.isnan(R[i, j]):\n",
    "            continue\n",
    "        loss += (R[i, j] - b_user[i] - b_item[j]) ** 2 * 0.5\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244e969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient of loss function\n",
    "def gradient(b_user, b_item, R, irow, jcol):\n",
    "    b_user_grad = np.zeros(b_user.shape)\n",
    "    b_item_grad = np.zeros(b_item.shape)\n",
    "    for i, j in zip(irow, jcol):\n",
    "        if np.isnan(R[i, j]):\n",
    "            continue\n",
    "        b_user_grad[i] += (R[i, j] - b_user[i] - b_item[j])\n",
    "        b_item_grad[j] += (R[i, j] - b_user[i] - b_item[j])\n",
    "\n",
    "    return b_user_grad, b_item_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da0e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent function\n",
    "def gradient_descent(R, b_user, b_item, irow, jcol, lr, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        b_user_grad, b_item_grad = gradient(b_user, b_item, R, irow, jcol)\n",
    "        prev_b_user = b_user.copy()\n",
    "        prev_b_item = b_item.copy()\n",
    "        b_user += lr * b_user_grad \n",
    "        b_item += lr * b_item_grad\n",
    "        if epoch % 10 == 0:\n",
    "            print('loss:', loss(b_user, b_item, R, irow, jcol))\n",
    "        # early stopping\n",
    "        if np.linalg.norm(b_user - prev_b_user) < 1e-2 and np.linalg.norm(b_item - prev_b_item) < 1e-2:\n",
    "            break\n",
    "\n",
    "    return b_user, b_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c573ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "R_copy, test_irow, test_jcol, val_irow, val_jcol, R_test_mask = split_data(R,irow,jcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4635cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize biases\n",
    "b_user = np.random.randn(943)\n",
    "b_item = np.random.randn(1682)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e08ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 386185.7983462831\n",
      "loss: 76323.74909153167\n",
      "loss: 57531.25698836898\n",
      "loss: 50753.165402464634\n",
      "loss: 47381.760636529274\n",
      "loss: 45438.80671651018\n",
      "loss: 44214.68400462271\n",
      "loss: 43394.20103475877\n",
      "loss: 42818.118457659\n",
      "loss: 42398.5033710425\n",
      "loss: 42083.487557364904\n",
      "loss: 41840.87778573936\n",
      "loss: 41649.86711670549\n",
      "loss: 41496.55544779305\n",
      "loss: 41371.39534164504\n",
      "loss: 41267.67041990933\n",
      "loss: 41180.555481552175\n",
      "loss: 41106.518080937836\n",
      "loss: 41042.92755682957\n",
      "loss: 40987.79382658571\n",
      "loss: 40939.58940786056\n",
      "loss: 40897.125994679125\n",
      "loss: 40859.467487061265\n",
      "loss: 40825.867801859065\n",
      "loss: 40795.725794759324\n",
      "loss: 40768.55216746724\n",
      "loss: 40743.94488148311\n",
      "loss: 40721.57068440759\n",
      "loss: 40701.15107972306\n",
      "loss: 40682.45156223512\n",
      "loss: 40665.273278620225\n",
      "loss: 40649.44650677464\n",
      "loss: 40634.82551219866\n",
      "loss: 40621.28445638629\n",
      "loss: 40608.7141159579\n",
      "loss: 40597.01923178159\n",
      "loss: 40586.11635157029\n",
      "loss: 40575.93206199765\n",
      "loss: 40566.401530538635\n",
      "loss: 40557.46729532891\n",
      "loss: 40549.078254978376\n",
      "loss: 40541.188820622316\n",
      "loss: 40533.758200450626\n",
      "loss: 40526.74979300985\n",
      "loss: 40520.13067035455\n",
      "loss: 40513.87113580142\n",
      "loss: 40507.944343939336\n",
      "loss: 40502.325972844854\n",
      "loss: 40496.99394029617\n",
      "loss: 40491.92815719486\n",
      "loss: 40487.11031262403\n",
      "loss: 40482.52368588709\n",
      "loss: 40478.152981642284\n",
      "loss: 40473.98418490815\n",
      "loss: 40470.00443317835\n",
      "loss: 40466.20190335189\n",
      "loss: 40462.56571152178\n",
      "loss: 40459.08582394889\n",
      "loss: 40455.752977789736\n",
      "loss: 40452.55861039331\n",
      "loss: 40449.49479606622\n",
      "loss: 40446.55418944858\n",
      "loss: 40443.729974699345\n",
      "loss: 40441.01581981422\n",
      "loss: 40438.405835487814\n",
      "loss: 40435.89453801454\n",
      "loss: 40433.476815772054\n",
      "loss: 40431.14789890047\n",
      "loss: 40428.90333182444\n",
      "loss: 40426.73894833232\n",
      "loss: 40424.650848923186\n",
      "loss: 40422.635380206906\n",
      "loss: 40420.6891161364\n",
      "loss: 40418.808840892045\n",
      "loss: 40416.99153325544\n",
      "loss: 40415.23435231886\n",
      "loss: 40413.53462441196\n",
      "loss: 40411.88983112507\n",
      "loss: 40410.29759831985\n",
      "loss: 40408.75568604493\n",
      "loss: 40407.2619792648\n",
      "loss: 40405.81447933152\n",
      "loss: 40404.41129613198\n",
      "loss: 40403.05064085711\n",
      "loss: 40401.73081931285\n",
      "loss: 40400.45022576865\n",
      "loss: 40399.20733724934\n",
      "loss: 40398.000708273146\n",
      "loss: 40396.82896596962\n",
      "loss: 40395.69080556131\n",
      "loss: 40394.58498617592\n",
      "loss: 40393.5103269491\n",
      "loss: 40392.46570342365\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "b_user, b_item = gradient_descent(R_copy, b_user, b_item, irow, jcol, 0.001, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ac82ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "def rmse(R, b_user, b_item, irow, jcol):\n",
    "    return np.sqrt(2 * loss(b_user, b_item, R, irow, jcol) / len(irow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b5b9470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non regularized loss function model RMSE: 0.9654828549684209\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE on test set\n",
    "print('Non regularized loss function model RMSE:' , rmse(R, b_user, b_item, test_irow, test_jcol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0afb74",
   "metadata": {},
   "source": [
    "## Regularized Loss Function Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "797ce2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized loss function\n",
    "def loss_reg(b_user, b_item, R, irow, jcol, lmbda):\n",
    "    loss = 0\n",
    "    for i, j in zip(irow, jcol):\n",
    "        if np.isnan(R[i, j]):\n",
    "            continue\n",
    "        loss += (R[i, j] - b_user[i] - b_item[j]) ** 2 * 0.5 + lmbda/2 * (b_user[i] ** 2 + b_item[j] ** 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d009acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized gradient of loss function\n",
    "def gradient_reg(b_user, b_item, R, irow, jcol, lmbda):\n",
    "    b_user_grad = np.zeros(b_user.shape)\n",
    "    b_item_grad = np.zeros(b_item.shape)\n",
    "    for i, j in zip(irow, jcol):\n",
    "        if np.isnan(R[i, j]):\n",
    "            continue\n",
    "        b_user_grad[i] += (R[i, j] - b_user[i] - b_item[j]) - lmbda * b_user[i]\n",
    "        b_item_grad[j] += (R[i, j] - b_user[i] - b_item[j]) - lmbda * b_item[j]\n",
    "\n",
    "    return b_user_grad, b_item_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58b90ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized gradient descent function\n",
    "def gradient_descent_reg(R, b_user, b_item, irow, jcol, lmbda, lr, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        b_user_grad, b_item_grad = gradient_reg(b_user, b_item, R, irow, jcol, lmbda)\n",
    "        prev_b_user = b_user.copy()\n",
    "        prev_b_item = b_item.copy()\n",
    "        b_user += lr * b_user_grad\n",
    "        b_item += lr * b_item_grad\n",
    "        if epoch % 10 == 0:\n",
    "            print('loss:', loss_reg(b_user, b_item, R, irow, jcol, lmbda))\n",
    "        # early stopping\n",
    "        if np.linalg.norm(b_user - prev_b_user) < 1e-2 and np.linalg.norm(b_item - prev_b_item) < 1e-2:\n",
    "            break\n",
    "\n",
    "    return b_user, b_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06c6114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize biases\n",
    "b_user = np.random.randn(943)\n",
    "b_item = np.random.randn(1682)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c954a2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 524891.4691990158\n",
      "loss: 116328.7734424634\n",
      "loss: 78974.79279840465\n",
      "loss: 65366.79033974722\n",
      "loss: 58259.29113117337\n",
      "loss: 53927.31553904509\n",
      "loss: 51046.72819013959\n",
      "loss: 49020.41228135431\n",
      "loss: 47536.96592583192\n",
      "loss: 46417.52809592836\n",
      "loss: 45552.151756448526\n",
      "loss: 44869.765172124455\n",
      "loss: 44322.59370498762\n",
      "loss: 43877.49129199245\n",
      "loss: 43510.847909074415\n",
      "loss: 43205.46591621918\n",
      "loss: 42948.574904866386\n",
      "loss: 42730.5316712571\n",
      "loss: 42543.94648343266\n",
      "loss: 42383.08231279436\n",
      "loss: 42243.4333042503\n",
      "loss: 42121.423607805846\n",
      "loss: 42014.18868008136\n",
      "loss: 41919.414133293176\n",
      "loss: 41835.215411857855\n",
      "loss: 44660.20140206312\n",
      "loss: 44586.95367466128\n",
      "loss: 44527.76434630795\n",
      "loss: 44474.52885727403\n",
      "loss: 44426.25691665524\n",
      "loss: 44382.2946569344\n",
      "loss: 44342.1133573763\n",
      "loss: 44305.26861319818\n",
      "loss: 44271.38162235332\n",
      "loss: 44240.12702078642\n",
      "loss: 44211.22381008666\n",
      "loss: 44184.428202465635\n",
      "loss: 44159.52783143126\n",
      "loss: 44136.337002597764\n",
      "loss: 44114.69276375388\n",
      "loss: 44094.45163227743\n",
      "loss: 44075.48685607418\n",
      "loss: 44057.686110982686\n",
      "loss: 44040.94955740428\n",
      "loss: 44025.188194066104\n",
      "loss: 44010.32245862139\n",
      "loss: 43996.28103410996\n",
      "loss: 43982.99982771999\n",
      "loss: 43970.421094265475\n",
      "loss: 43958.49268160097\n",
      "loss: 72456.20653603484\n",
      "loss: 71669.45404397238\n",
      "loss: 71593.03689645801\n",
      "loss: 71554.36374306383\n",
      "loss: 71526.79967240454\n",
      "loss: 71504.59625444564\n",
      "loss: 71485.59776222792\n",
      "loss: 71468.76880785718\n",
      "loss: 71453.53435979264\n",
      "loss: 71439.54261147669\n",
      "loss: 71426.56245651326\n",
      "loss: 71414.43328128412\n",
      "loss: 71403.0381316653\n",
      "loss: 71392.2884158549\n",
      "loss: 71382.11473223314\n",
      "loss: 71372.46113596148\n",
      "loss: 71363.28142461655\n",
      "loss: 71354.53665443129\n",
      "loss: 71346.1934315256\n",
      "loss: 71338.222705384\n",
      "loss: 71330.59889651446\n",
      "loss: 71323.2992517524\n",
      "loss: 71316.30335810062\n",
      "loss: 71309.59276921065\n",
      "loss: 71303.15071338939\n",
      "loss: 297335.37965707615\n",
      "loss: 257226.7092263613\n",
      "loss: 254430.4604528081\n",
      "loss: 253432.88833660315\n",
      "loss: 252954.16980287235\n",
      "loss: 252692.40484650337\n",
      "loss: 252537.55265773003\n",
      "loss: 252440.71028934486\n",
      "loss: 252377.42595126873\n",
      "loss: 252334.4701807294\n",
      "loss: 252304.27454226912\n",
      "loss: 252282.32735053363\n",
      "loss: 252265.8524246337\n",
      "loss: 252253.0970021727\n",
      "loss: 252242.92988175043\n",
      "loss: 252234.6064400539\n",
      "loss: 252227.62733200027\n",
      "loss: 252221.65158331956\n",
      "loss: 252216.4421217559\n",
      "loss: 252211.83108055586\n",
      "loss: 252207.6973743075\n",
      "loss: 252203.9520110094\n",
      "loss: 252200.52834787554\n",
      "loss: 252197.37554563186\n",
      "loss: 252194.45411610472\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimization to find best lambda on validation set\n",
    "best_rmse = float('inf')\n",
    "best_lmbda = 0\n",
    "for lmbda in [0.001, 0.01, 0.1, 1]:\n",
    "    b_user, b_item = gradient_descent_reg(R_copy, b_user, b_item, irow, jcol, lmbda, 0.0005, 250)\n",
    "    rmse_val = rmse(R, b_user, b_item, val_irow, val_jcol)\n",
    "    if rmse_val < best_rmse:\n",
    "        best_rmse = rmse_val\n",
    "        best_lmbda = lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "600c0e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f07ce012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 93096.79445230114\n",
      "loss: 50714.63749871168\n",
      "loss: 47737.6028197279\n",
      "loss: 46673.455808257044\n",
      "loss: 46104.61484935234\n",
      "loss: 45749.550480934246\n",
      "loss: 45508.61291633486\n",
      "loss: 45336.21472594272\n",
      "loss: 45208.151096547525\n",
      "loss: 45110.28148102286\n",
      "loss: 45033.780836569334\n",
      "loss: 44972.8659066574\n",
      "loss: 44923.59955015559\n",
      "loss: 44883.217218870755\n",
      "loss: 44849.72707403505\n",
      "loss: 44821.66237485197\n",
      "loss: 44797.922707181846\n",
      "loss: 44777.66909210223\n",
      "loss: 44760.2528623619\n",
      "loss: 44745.16631535431\n",
      "loss: 44732.00776960806\n",
      "loss: 44720.45636670428\n",
      "loss: 44710.25360334301\n",
      "loss: 44701.18959805646\n",
      "loss: 44693.09274512882\n",
      "loss: 44685.82182884627\n",
      "loss: 44679.25994964616\n",
      "loss: 44673.30980139378\n",
      "loss: 44667.8899676672\n",
      "loss: 44662.93199452516\n",
      "loss: 44658.37806051201\n",
      "loss: 44654.179109969475\n",
      "loss: 44650.29334855906\n",
      "loss: 44646.68502400737\n",
      "loss: 44643.32343292327\n",
      "loss: 44640.182107883564\n",
      "loss: 44637.23814908124\n",
      "loss: 44634.47167251156\n",
      "loss: 44631.86535254679\n",
      "loss: 44629.40404133409\n",
      "loss: 44627.07445095442\n"
     ]
    }
   ],
   "source": [
    "# Regularized gradient descent with best lambda\n",
    "b_user, b_item = gradient_descent_reg(R_test_mask, b_user, b_item, irow, jcol, best_lmbda, 0.0005, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63742afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for regularized RMSE on test set with best model\n",
    "def rmse_reg(R, b_user, b_item, irow, jcol, lmbda):\n",
    "    return np.sqrt(2 * loss_reg(b_user, b_item, R, irow, jcol, lmbda) / len(irow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02139e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized RMSE: 1.005215290741836\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE on test set\n",
    "print('Regularized RMSE:' , rmse_reg(R, b_user, b_item, test_irow, test_jcol, best_lmbda))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
